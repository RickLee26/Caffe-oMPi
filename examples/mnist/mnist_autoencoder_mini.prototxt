name: "MNISTAutoencoder-mini"
layer{
	name: "data"
	type: "Data"
	top:  "data"
	include {
	  phase: TRAIN
	}
    transform_param {
      scale: 0.0039215684
    }
	data_param {
	  source: "examples/mnist/mnist_train_lmdb"
	  batch_size: 128
	  backend: LMDB
	}
}

layer {
	name: "data"
	type: "Data"
	top:  "data"
	include {
	  phase: TEST
	}
    transform_param {
      scale: 0.0039215684
    }
	data_param {
	  source: "examples/mnist/mnist_test_lmdb"
	  batch_size: 128
	  backend: LMDB
	}
}

layer {
	name: "flatdata"
	type: "Flatten"
	bottom: "data"
	top: "flatdata"
}

layer {
	name: "encode"
	type: "InnerProduct"
	bottom: "data"
	top: "encode"
	param {
	  lr_mult: 1
	  decay_mult: 1
	}
	param {
	  lr_mult: 1
	  decay_mult: 0
	}
	inner_product_param {
	  num_output: 1024
	  weight_filler {
	    type: "xavier"
	  }
	  bias_filler {
	    type: "constant"
	    value: 0
	  }
	}
}

layer {
	name: "encodeactive"
	type: "Sigmoid"
	bottom: "encode"
	top: "encodeactive"
}

layer {
	name: "decode"
	type: "InnerProduct"
	bottom: "encodeactive"
	top: "decode"
	param {
	  lr_mult: 1
	  decay_mult: 1
	}
	param {
	  lr_mult: 1
	  decay_mult: 0
	}
	inner_product_param {
	  num_output: 784
	  weight_filler {
	    type: "xavier"
	  }
	  bias_filler {
	    type: "constant"
	    value: 0
	  }
	}
}

layer {
    name: "loss"
    type: "SigmoidCrossEntropyLoss"
    bottom: "decode"
    bottom: "flatdata"
    top: "cross_entropy_loss"
    loss_weight: 1
}


layer {
	name: "decodeactive"
	type: "Sigmoid"
	bottom: "decode"
	top: "decodeactive"
}

layer {
	name: "loss"
	type: "EuclideanLoss"
	bottom: "decodeactive"
	bottom: "flatdata"
	top: "l2_error"
	loss_weight: 0
}